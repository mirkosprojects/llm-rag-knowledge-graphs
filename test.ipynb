{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39baf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama and Huggingface packages\n",
    "%pip install llama-index-llms-ollama llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f31f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use local model\n",
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model=\"llama3.2:latest\", request_timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba254a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/intelSys/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 describes a dog as a loyal companion with unique traits and personalities. Dogs provide comfort, protection, and love to their owners, making them beloved pets worldwide.\n",
      "\n",
      "Document 2 delves into ancient Roman history, describing the city of Rome as the heart of the vast empire. The Romans were skilled engineers who built iconic structures and an extensive network of roads and aqueducts that connected their territories, ultimately establishing a legacy in art, law, and governance.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader('files').load_data()\n",
    "\n",
    "# Set up local embeddings (you can specify a different model too)\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Build the index with local embeddings\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "\n",
    "# Set up query engine using Ollama\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "\n",
    "# Query\n",
    "response = query_engine.query(\"Summarize each document in a few sentences.\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcd2582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenAI models for embeddings\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# documents = SimpleDirectoryReader('files').load_data()\n",
    "# index = VectorStoreIndex.from_documents(documents)\n",
    "# query_engine = index.as_query_engine()\n",
    "# response = query_engine.query(\"summarize each document in a few sentences\")\n",
    "\n",
    "# print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelSys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
